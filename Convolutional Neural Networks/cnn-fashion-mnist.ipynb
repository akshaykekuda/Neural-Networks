{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CSE5526_Lab4_AkshayKekuda.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBFQZ--ju_nQ"
      },
      "source": [
        "# Lab 4\n",
        "\n",
        "Disclaimer: The code has been built upon the starter code provided by Dr. Fosler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVcdbKGfu7Mt"
      },
      "source": [
        "# import standard PyTorch modules\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.tensorboard import SummaryWriter # TensorBoard support\n",
        "\n",
        "\n",
        "# import torchvision module to handle image manipulation\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_ra6PVjwCoa"
      },
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtphcZeJvs8x"
      },
      "source": [
        "# Use standard FashionMNIST dataset\n",
        "train_set = torchvision.datasets.FashionMNIST(\n",
        "    root = './data/FashionMNIST',\n",
        "    train = True,\n",
        "    download = True,\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor()                                 \n",
        "    ])\n",
        ")\n",
        "\n",
        "test_set = torchvision.datasets.FashionMNIST(\n",
        "    root = './data/FashionMNIST',\n",
        "    train = False,\n",
        "    download = False,\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor()                                 \n",
        "    ])\n",
        ")"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUUNmoPV2KIJ",
        "outputId": "13865f44-08c8-4262-f564-687b641c99ce"
      },
      "source": [
        "train_set.targets"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([9, 0, 0,  ..., 3, 0, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zK-fU3infjIl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93a70c2b-62d2-4560-f283-02e594e2e106"
      },
      "source": [
        "train_set.data[:][:][:].shape"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([60000, 28, 28])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYmzeeyHxDCs"
      },
      "source": [
        "## Linear 2 Layer DNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vV3pNFfr5Dzt"
      },
      "source": [
        "# Build the neural network, expand on top of nn.Module\n",
        "class Linear_Network(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    # define layers\n",
        "    self.fc1 = nn.Linear(in_features=28*28,out_features=200)\n",
        "    self.fc2 = nn.Linear(in_features=200,out_features=10)\n",
        "\n",
        "\n",
        "  # define forward function\n",
        "  def forward(self, t):\n",
        "    # fc 1\n",
        "    t=t.reshape(-1,28*28)\n",
        "    t=self.fc1(t)\n",
        "    t=F.relu(t)\n",
        "\n",
        "    # fc 2\n",
        "    t=self.fc2(t)\n",
        "    # don't need softmax here since we'll use cross-entropy as activation.\n",
        "\n",
        "    return t"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXzz54KsNfZf"
      },
      "source": [
        "## Baseline CNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVhVxfNFwRLd"
      },
      "source": [
        "# Build the neural network, expand on top of nn.Module\n",
        "class Network(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    # define layers\n",
        "    self.fc1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=(5,5))\n",
        "    self.fc2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=(5,5))\n",
        "    self.fc3 = nn.Linear(in_features=4*4*12,out_features=120)\n",
        "    self.fc4 = nn.Linear(in_features=120,out_features=60)\n",
        "    self.fc5 = nn.Linear(in_features=60,out_features=10)\n",
        "    self.mxpool = nn.MaxPool2d(kernel_size=(2,2),stride = (2,2))\n",
        "\n",
        "  # define forward function\n",
        "  def forward(self, t):\n",
        "    # fc 1\n",
        "    t=self.fc1(t)\n",
        "    t=F.relu(t)\n",
        "    t = self.mxpool(t)\n",
        "    # fc 2\n",
        "    t=self.fc2(t)\n",
        "    t=F.relu(t)\n",
        "    t = self.mxpool(t)\n",
        "\n",
        "    t = torch.flatten(t,1)\n",
        "    t = self.fc3(t)\n",
        "    t = F.relu(t)\n",
        "    t = self.fc4(t)\n",
        "    t = F.relu(t)\n",
        "    t = self.fc5(t)\n",
        "    # t = F.log_softmax(t, dim=1)    \n",
        "    # don't need softmax here since we'll use cross-entropy as activation.\n",
        "\n",
        "    return t"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzhKnPcSd3RP"
      },
      "source": [
        "## Accuracy calculator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuKEqezweA_S"
      },
      "source": [
        "def get_accuracy(model,dataloader):\n",
        "  count=0\n",
        "  correct=0\n",
        "\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for batch in dataloader:\n",
        "      images = batch[0]\n",
        "      labels = batch[1]\n",
        "      preds=model(images)\n",
        "      batch_correct=preds.argmax(dim=1).eq(labels).sum().item()\n",
        "      batch_count=len(batch[0])\n",
        "      count+=batch_count\n",
        "      correct+=batch_correct\n",
        "  model.train()\n",
        "  return correct/count\n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIkypu3WdfiV"
      },
      "source": [
        "## Evaluating the 2 Layer Linear DNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lf8DFWm1Ocdw"
      },
      "source": [
        "def train_test_network(network, epochs):\n",
        "    # set the network to training mode\n",
        "  loader = torch.utils.data.DataLoader(train_set, batch_size = batch_size)\n",
        "  optimizer = optim.Adam(network.parameters(), lr=lr)\n",
        "  network.train()\n",
        "  for epoch in range(epochs):\n",
        "    for batch in loader:\n",
        "      images = batch[0]\n",
        "      labels = batch[1]\n",
        "      preds = network(images)\n",
        "      loss = F.cross_entropy(preds, labels)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "    print('Epoch {0}: train set accuracy {1}'.format(epoch,get_accuracy(network,loader)))\n",
        "\n",
        "  test_loader = torch.utils.data.DataLoader(test_set, batch_size = batch_size)\n",
        "  print('Epoch {0}: test set accuracy {1}'.format(epoch,get_accuracy(network,test_loader)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cx8ZtC2TKpwV",
        "outputId": "ed143ec2-7059-477f-f065-e7d00d6cdb6a"
      },
      "source": [
        "network = Linear_Network()\n",
        "train_test_network(network, epochs=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: train set accuracy 0.7971166666666667\n",
            "Epoch 1: train set accuracy 0.8341\n",
            "Epoch 2: train set accuracy 0.84615\n",
            "Epoch 3: train set accuracy 0.8538666666666667\n",
            "Epoch 4: train set accuracy 0.8590666666666666\n",
            "Epoch 5: train set accuracy 0.8640833333333333\n",
            "Epoch 6: train set accuracy 0.8677\n",
            "Epoch 7: train set accuracy 0.8714\n",
            "Epoch 8: train set accuracy 0.8743666666666666\n",
            "Epoch 9: train set accuracy 0.8775666666666667\n",
            "Epoch 9: test set accuracy 0.8601\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoc6mNvCOZu-"
      },
      "source": [
        "## Evaluating the Baseline CNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vq2sgd0sH5mr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60683c37-cdbb-4e7b-d222-14c302a45bb4"
      },
      "source": [
        "lr=0.001\n",
        "batch_size=1000\n",
        "shuffle=True\n",
        "epochs=10\n",
        "\n",
        "network = Network()\n",
        "loader = torch.utils.data.DataLoader(train_set, batch_size = batch_size)\n",
        "optimizer = optim.Adam(network.parameters(), lr=lr)\n",
        "\n",
        "# set the network to training mode\n",
        "network.train()\n",
        "for epoch in range(epochs):\n",
        "  for batch in loader:\n",
        "    images = batch[0]\n",
        "    labels = batch[1]\n",
        "    preds = network(images)\n",
        "    loss = F.cross_entropy(preds, labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  print('Epoch {0}: train set accuracy {1}'.format(epoch,get_accuracy(network,loader)))\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size = batch_size)\n",
        "print('Epoch {0}: test set accuracy {1}'.format(epoch,get_accuracy(network,test_loader)))\n",
        "\n",
        "\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: train set accuracy 0.6918666666666666\n",
            "Epoch 1: train set accuracy 0.7322666666666666\n",
            "Epoch 2: train set accuracy 0.75585\n",
            "Epoch 3: train set accuracy 0.7796333333333333\n",
            "Epoch 4: train set accuracy 0.7984\n",
            "Epoch 5: train set accuracy 0.81245\n",
            "Epoch 6: train set accuracy 0.82285\n",
            "Epoch 7: train set accuracy 0.83085\n",
            "Epoch 8: train set accuracy 0.8382333333333334\n",
            "Epoch 9: train set accuracy 0.8439\n",
            "Epoch 9: test set accuracy 0.8342\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyFG9CnnOjc8"
      },
      "source": [
        "## Experiments with different Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_k029vvaPx3a"
      },
      "source": [
        "1. Introduce zero padding and increase the number of feature maps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eYrIbUvz-t1"
      },
      "source": [
        "# Build the neural network, expand on top of nn.Module\n",
        "class Network1(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    # define layers\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(3,3), padding=1)\n",
        "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3,3))\n",
        "    self.fc3 = nn.Linear(in_features=6*6*64,out_features=120)\n",
        "    self.fc4 = nn.Linear(in_features=120,out_features=60)\n",
        "    self.fc5 = nn.Linear(in_features=60,out_features=10)\n",
        "    self.mxpool = nn.MaxPool2d(kernel_size=(2,2),stride = (2,2))\n",
        "\n",
        "  # define forward function\n",
        "  def forward(self, t):\n",
        "    # fc 1\n",
        "    t=self.conv1(t)\n",
        "    t=F.relu(t)\n",
        "    t = self.mxpool(t)\n",
        "    # fc 2\n",
        "    t=self.conv2(t)\n",
        "    t=F.relu(t)\n",
        "    t = self.mxpool(t)\n",
        "\n",
        "    t = torch.flatten(t,1)\n",
        "    t = self.fc3(t)\n",
        "    t = F.relu(t)\n",
        "    t = self.fc4(t)\n",
        "    t = F.relu(t)\n",
        "    t = self.fc5(t)\n",
        "    # t = F.log_softmax(t, dim=1)    \n",
        "\n",
        "    return t"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MibgO_nO2ECB",
        "outputId": "b9364956-fa7c-41f7-ebea-f76cd38de2ab"
      },
      "source": [
        "lr=0.001\n",
        "batch_size=1000\n",
        "shuffle=True\n",
        "epochs=10\n",
        "\n",
        "network = Network1()\n",
        "loader = torch.utils.data.DataLoader(train_set, batch_size = batch_size)\n",
        "optimizer = optim.Adam(network.parameters(), lr=lr)\n",
        "\n",
        "# set the network to training mode\n",
        "network.train()\n",
        "for epoch in range(epochs):\n",
        "  for batch in loader:\n",
        "    images = batch[0]\n",
        "    labels = batch[1]\n",
        "    preds = network(images)\n",
        "    loss = F.cross_entropy(preds, labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  print('Epoch {0}: train set accuracy {1}'.format(epoch,get_accuracy(network,loader)))\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size = batch_size)\n",
        "print('Epoch {0}: test set accuracy {1}'.format(epoch,get_accuracy(network,test_loader)))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: train set accuracy 0.7525666666666667\n",
            "Epoch 1: train set accuracy 0.8144166666666667\n",
            "Epoch 2: train set accuracy 0.84085\n",
            "Epoch 3: train set accuracy 0.8593833333333334\n",
            "Epoch 4: train set accuracy 0.8655\n",
            "Epoch 5: train set accuracy 0.8730833333333333\n",
            "Epoch 6: train set accuracy 0.8812666666666666\n",
            "Epoch 7: train set accuracy 0.8865166666666666\n",
            "Epoch 8: train set accuracy 0.8904\n",
            "Epoch 9: train set accuracy 0.8940333333333333\n",
            "Epoch 9: test set accuracy 0.8846\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrMPpDYfQED8"
      },
      "source": [
        "2. Introduce dropout layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TPTwOFi8-b6"
      },
      "source": [
        "# Build the neural network, expand on top of nn.Module\n",
        "class Network2(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    # define layers\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(3,3), padding=1)\n",
        "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3,3))\n",
        "    self.fc3 = nn.Linear(in_features=6*6*64,out_features=120)\n",
        "    self.fc4 = nn.Linear(in_features=120,out_features=60)\n",
        "    self.fc5 = nn.Linear(in_features=60,out_features=10)\n",
        "    self.mxpool = nn.MaxPool2d(kernel_size=(2,2),stride = (2,2))\n",
        "    self.drop = nn.Dropout2d(0.25)\n",
        "\n",
        "  # define forward function\n",
        "  def forward(self, t):\n",
        "    # fc 1\n",
        "    t=self.conv1(t)\n",
        "    t=F.relu(t)\n",
        "    t = self.mxpool(t)\n",
        "    t = self.drop(t)\n",
        "    # fc 2\n",
        "    t=self.conv2(t)\n",
        "    t=F.relu(t)\n",
        "    t = self.mxpool(t)\n",
        "\n",
        "    t = torch.flatten(t,1)\n",
        "    t = self.fc3(t)\n",
        "    t = F.relu(t)\n",
        "    t = self.drop(t)\n",
        "    t = self.fc4(t)\n",
        "    t = F.relu(t)\n",
        "    t = self.fc5(t)\n",
        "    # t = F.log_softmax(t, dim=1)    \n",
        "\n",
        "    return t"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bc476-ZI9cZK",
        "outputId": "dfec8911-7f01-4385-dfb7-308ec1ab1c8e"
      },
      "source": [
        "network = Network2()\n",
        "loader = torch.utils.data.DataLoader(train_set, batch_size = batch_size)\n",
        "optimizer = optim.Adam(network.parameters(), lr=lr)\n",
        "\n",
        "# set the network to training mode\n",
        "network.train()\n",
        "for epoch in range(epochs):\n",
        "  for batch in loader:\n",
        "    images = batch[0]\n",
        "    labels = batch[1]\n",
        "    preds = network(images)\n",
        "    loss = F.cross_entropy(preds, labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  print('Epoch {0}: train set accuracy {1}'.format(epoch,get_accuracy(network,loader)))\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size = batch_size)\n",
        "print('Epoch {0}: test set accuracy {1}'.format(epoch,get_accuracy(network,test_loader)))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: train set accuracy 0.7626666666666667\n",
            "Epoch 1: train set accuracy 0.8218833333333333\n",
            "Epoch 2: train set accuracy 0.8464666666666667\n",
            "Epoch 3: train set accuracy 0.8650833333333333\n",
            "Epoch 4: train set accuracy 0.8725\n",
            "Epoch 5: train set accuracy 0.8824333333333333\n",
            "Epoch 6: train set accuracy 0.8877666666666667\n",
            "Epoch 7: train set accuracy 0.8896666666666667\n",
            "Epoch 8: train set accuracy 0.89715\n",
            "Epoch 9: train set accuracy 0.8991833333333333\n",
            "Epoch 9: test set accuracy 0.8899\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ahb_tsxpQPm8"
      },
      "source": [
        "This model also performs good as we see almost the same train and test set accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXTYFabrQX5d"
      },
      "source": [
        "3. Increase the size of the linear layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ickA9SzOOlUP"
      },
      "source": [
        "# Build the neural network, expand on top of nn.Module\n",
        "class Network3(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    # define layers\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(3,3), padding=1)\n",
        "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3,3))\n",
        "    self.fc3 = nn.Linear(in_features=6*6*64,out_features=600)\n",
        "    self.fc4 = nn.Linear(in_features=600,out_features=120)\n",
        "    self.fc5 = nn.Linear(in_features=120,out_features=10)\n",
        "    self.mxpool = nn.MaxPool2d(kernel_size=(2,2),stride = (2,2))\n",
        "    self.drop = nn.Dropout2d(0.25)\n",
        "\n",
        "  # define forward function\n",
        "  def forward(self, t):\n",
        "    # fc 1\n",
        "    t=self.conv1(t)\n",
        "    t=F.relu(t)\n",
        "    t = self.mxpool(t)\n",
        "    t = self.drop(t)\n",
        "    # fc 2\n",
        "    t=self.conv2(t)\n",
        "    t=F.relu(t)\n",
        "    t = self.mxpool(t)\n",
        "\n",
        "    t = torch.flatten(t,1)\n",
        "    t = self.fc3(t)\n",
        "    t = F.relu(t)\n",
        "    t = self.drop(t)\n",
        "    t = self.fc4(t)\n",
        "    t = F.relu(t)\n",
        "    t = self.fc5(t)\n",
        "    # t = F.log_softmax(t, dim=1)    \n",
        "\n",
        "    return t"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sfm6Cq4VO6Sd",
        "outputId": "649fd7d4-7cad-4be3-c4ec-2d69d29c0ede"
      },
      "source": [
        "network = Network3()\n",
        "train_test_network(network)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: train set accuracy 0.79345\n",
            "Epoch 1: train set accuracy 0.8428333333333333\n",
            "Epoch 2: train set accuracy 0.8667166666666667\n",
            "Epoch 3: train set accuracy 0.8826166666666667\n",
            "Epoch 4: train set accuracy 0.89135\n",
            "Epoch 5: train set accuracy 0.89755\n",
            "Epoch 6: train set accuracy 0.9056666666666666\n",
            "Epoch 7: train set accuracy 0.9067333333333333\n",
            "Epoch 8: train set accuracy 0.9129166666666667\n",
            "Epoch 9: train set accuracy 0.9158333333333334\n",
            "Epoch 9: test set accuracy 0.899\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vz3HWNTwQ1o_"
      },
      "source": [
        "4. Batch normalization before Layer 2 and Layer 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4UK15LQPFpq"
      },
      "source": [
        "# Build the neural network, expand on top of nn.Module\n",
        "class Network4(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    # define layers\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(3,3), padding=1)\n",
        "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3,3))\n",
        "    self.fc3 = nn.Linear(in_features=6*6*64,out_features=600)\n",
        "    self.fc4 = nn.Linear(in_features=600,out_features=120)\n",
        "    self.fc5 = nn.Linear(in_features=120,out_features=10)\n",
        "    self.mxpool = nn.MaxPool2d(kernel_size=(2,2),stride = (2,2))\n",
        "    self.drop = nn.Dropout2d(0.25)\n",
        "    self.batchnorm1 = nn.BatchNorm2d(32)\n",
        "    self.batchnorm2 = nn.BatchNorm2d(64)\n",
        "\n",
        "\n",
        "  # define forward function\n",
        "  def forward(self, t):\n",
        "    # conv1 1\n",
        "    t=self.conv1(t)\n",
        "    t=F.relu(t)\n",
        "    t = self.mxpool(t)\n",
        "    t = self.batchnorm1(t)\n",
        "\n",
        "    # conv 2\n",
        "    t=self.conv2(t)\n",
        "    t=F.relu(t)\n",
        "    t = self.mxpool(t)\n",
        "    t = self.batchnorm2(t)\n",
        "\n",
        "    t = torch.flatten(t,1)\n",
        "    t = self.fc3(t)\n",
        "    t = F.relu(t)\n",
        "    t = self.drop(t)\n",
        "    t = self.fc4(t)\n",
        "    t = F.relu(t)\n",
        "    t = self.fc5(t)\n",
        "    # t = F.log_softmax(t, dim=1)    \n",
        "\n",
        "    return t"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goMM7r35UCcx",
        "outputId": "2f7840aa-ca63-4d64-b745-25c16d4209ac"
      },
      "source": [
        "network = Network4()\n",
        "train_test_network(network, epochs=10)"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: train set accuracy 0.89255\n",
            "Epoch 1: train set accuracy 0.9190666666666667\n",
            "Epoch 2: train set accuracy 0.9437333333333333\n",
            "Epoch 3: train set accuracy 0.9544\n",
            "Epoch 4: train set accuracy 0.9582666666666667\n",
            "Epoch 5: train set accuracy 0.9669833333333333\n",
            "Epoch 6: train set accuracy 0.9752166666666666\n",
            "Epoch 7: train set accuracy 0.9798\n",
            "Epoch 8: train set accuracy 0.9812166666666666\n",
            "Epoch 9: train set accuracy 0.9819833333333333\n",
            "Epoch 9: test set accuracy 0.9128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMtgcxsXQ7kF"
      },
      "source": [
        "As can be seen in the results there is overfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s29i4MXYRGl4"
      },
      "source": [
        "4.1 Batch normalization immediatly after the convolution layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OqxAl5ZGlQD"
      },
      "source": [
        "# Build the neural network, expand on top of nn.Module\n",
        "class Network4_1(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    # define layers\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(3,3), padding=1)\n",
        "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3,3))\n",
        "    self.fc3 = nn.Linear(in_features=6*6*64,out_features=600)\n",
        "    self.fc4 = nn.Linear(in_features=600,out_features=120)\n",
        "    self.fc5 = nn.Linear(in_features=120,out_features=10)\n",
        "    self.mxpool = nn.MaxPool2d(kernel_size=(2,2),stride = (2,2))\n",
        "    self.drop = nn.Dropout2d(0.25)\n",
        "    self.batchnorm1 = nn.BatchNorm2d(32)\n",
        "    self.batchnorm2 = nn.BatchNorm2d(64)\n",
        "\n",
        "\n",
        "  # define forward function\n",
        "  def forward(self, t):\n",
        "    # conv1 1\n",
        "    t=self.conv1(t)\n",
        "    t = self.batchnorm1(t)\n",
        "    t=F.relu(t)\n",
        "    t = self.mxpool(t)\n",
        "\n",
        "    # conv 2\n",
        "    t=self.conv2(t)\n",
        "    t = self.batchnorm2(t)\n",
        "\n",
        "    t=F.relu(t)\n",
        "    t = self.mxpool(t)\n",
        "\n",
        "    t = torch.flatten(t,1)\n",
        "    t = self.fc3(t)\n",
        "    t = F.relu(t)\n",
        "    t = self.drop(t)\n",
        "    t = self.fc4(t)\n",
        "    t = F.relu(t)\n",
        "    t = self.fc5(t)\n",
        "    # t = F.log_softmax(t, dim=1)    \n",
        "\n",
        "    return t"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGqFpcTDGtQa",
        "outputId": "15975471-018a-421f-9304-f5b5153d9297"
      },
      "source": [
        "network = Network4_1()\n",
        "train_test_network(network, epochs=10)"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: train set accuracy 0.8748833333333333\n",
            "Epoch 1: train set accuracy 0.9016833333333333\n",
            "Epoch 2: train set accuracy 0.9124833333333333\n",
            "Epoch 3: train set accuracy 0.9234333333333333\n",
            "Epoch 4: train set accuracy 0.9285666666666667\n",
            "Epoch 5: train set accuracy 0.9366166666666667\n",
            "Epoch 6: train set accuracy 0.9332833333333334\n",
            "Epoch 7: train set accuracy 0.9205666666666666\n",
            "Epoch 8: train set accuracy 0.9479833333333333\n",
            "Epoch 9: train set accuracy 0.9549\n",
            "Epoch 9: test set accuracy 0.9186\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FrWn8JdRSz2"
      },
      "source": [
        "5. Increasing the number of epochs to 20"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05W54kjMjdyK"
      },
      "source": [
        "# Build the neural network, expand on top of nn.Module\n",
        "class Network5(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    # define layers\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(3,3), padding=1)\n",
        "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3,3))\n",
        "    self.fc3 = nn.Linear(in_features=6*6*64,out_features=600)\n",
        "    self.fc4 = nn.Linear(in_features=600,out_features=120)\n",
        "    self.fc5 = nn.Linear(in_features=120,out_features=10)\n",
        "    self.mxpool = nn.MaxPool2d(kernel_size=(2,2),stride = (2,2))\n",
        "    self.drop = nn.Dropout2d(0.25)\n",
        "    self.batchnorm1 = nn.BatchNorm2d(32)\n",
        "    self.batchnorm2 = nn.BatchNorm2d(64)\n",
        "\n",
        "\n",
        "  # define forward function\n",
        "  def forward(self, t):\n",
        "    # conv1 1\n",
        "    t=self.conv1(t)\n",
        "    # t = self.batchnorm1(t)\n",
        "    t=F.relu(t)\n",
        "    t = self.mxpool(t)\n",
        "    t = self.drop(t)\n",
        "    # conv 2\n",
        "    t=self.conv2(t)\n",
        "    # t = self.batchnorm2(t)\n",
        "    t=F.relu(t)\n",
        "    t = self.mxpool(t)\n",
        "    t = self.drop(t)\n",
        "\n",
        "    t = torch.flatten(t,1)\n",
        "    t = self.fc3(t)\n",
        "    t = F.relu(t)\n",
        "    t = self.drop(t)\n",
        "    t = self.fc4(t)\n",
        "    t = F.relu(t)\n",
        "    t = self.fc5(t)\n",
        "    # t = F.log_softmax(t, dim=1)    \n",
        "\n",
        "    return t"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dx4ylYafs81C",
        "outputId": "20f49381-6bf8-4cf5-c86b-b7875406e4de"
      },
      "source": [
        "network = Network5()\n",
        "train_test_network(network, epochs=20)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: train set accuracy 0.7832666666666667\n",
            "Epoch 1: train set accuracy 0.84505\n",
            "Epoch 2: train set accuracy 0.8646333333333334\n",
            "Epoch 3: train set accuracy 0.8793166666666666\n",
            "Epoch 4: train set accuracy 0.8865333333333333\n",
            "Epoch 5: train set accuracy 0.8944833333333333\n",
            "Epoch 6: train set accuracy 0.9029\n",
            "Epoch 7: train set accuracy 0.9061166666666667\n",
            "Epoch 8: train set accuracy 0.9114833333333333\n",
            "Epoch 9: train set accuracy 0.9166166666666666\n",
            "Epoch 10: train set accuracy 0.9188666666666667\n",
            "Epoch 11: train set accuracy 0.9218166666666666\n",
            "Epoch 12: train set accuracy 0.9255166666666667\n",
            "Epoch 13: train set accuracy 0.9300166666666667\n",
            "Epoch 14: train set accuracy 0.9325\n",
            "Epoch 15: train set accuracy 0.9344833333333333\n",
            "Epoch 16: train set accuracy 0.9376\n",
            "Epoch 17: train set accuracy 0.9385\n",
            "Epoch 18: train set accuracy 0.9399166666666666\n",
            "Epoch 19: train set accuracy 0.9423\n",
            "Epoch 19: test set accuracy 0.9179\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1chmIUCRo6-"
      },
      "source": [
        "6. Increasing the kernel size of the baseline model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dm9jMgVG5Qoi"
      },
      "source": [
        "# Build the neural network, expand on top of nn.Module\n",
        "class Network6(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    # define layers\n",
        "    self.fc1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=(5,5))\n",
        "    self.fc2 = nn.Conv2d(in_channels=16, out_channels=64, kernel_size=(5,5))\n",
        "    self.fc3 = nn.Linear(in_features=4*4*64,out_features=120)\n",
        "    self.fc4 = nn.Linear(in_features=120,out_features=60)\n",
        "    self.fc5 = nn.Linear(in_features=60,out_features=10)\n",
        "    self.mxpool = nn.MaxPool2d(kernel_size=(2,2),stride = (2,2))\n",
        "\n",
        "  # define forward function\n",
        "  def forward(self, t):\n",
        "    # fc 1\n",
        "    t=self.fc1(t)\n",
        "    t=F.relu(t)\n",
        "    t = self.mxpool(t)\n",
        "    # fc 2\n",
        "    t=self.fc2(t)\n",
        "    t=F.relu(t)\n",
        "    t = self.mxpool(t)\n",
        "\n",
        "    t = torch.flatten(t,1)\n",
        "    t = self.fc3(t)\n",
        "    t = F.relu(t)\n",
        "    t = self.fc4(t)\n",
        "    t = F.relu(t)\n",
        "    t = self.fc5(t)\n",
        "    # t = F.log_softmax(t, dim=1)    \n",
        "    # don't need softmax here since we'll use cross-entropy as activation.\n",
        "\n",
        "    return t"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAuNJTfi8TWZ",
        "outputId": "7033fc45-590c-4edf-a572-1217a0dd8178"
      },
      "source": [
        "network = Network6()\n",
        "train_test_network(network, epochs=10)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: train set accuracy 0.7303833333333334\n",
            "Epoch 1: train set accuracy 0.7711333333333333\n",
            "Epoch 2: train set accuracy 0.80215\n",
            "Epoch 3: train set accuracy 0.8206666666666667\n",
            "Epoch 4: train set accuracy 0.8393166666666667\n",
            "Epoch 5: train set accuracy 0.8504333333333334\n",
            "Epoch 6: train set accuracy 0.85875\n",
            "Epoch 7: train set accuracy 0.86375\n",
            "Epoch 8: train set accuracy 0.8726166666666667\n",
            "Epoch 9: train set accuracy 0.8768666666666667\n",
            "Epoch 9: test set accuracy 0.8682\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GihPq14qOuxj"
      },
      "source": [
        "## Variation 1 Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGvitRljPAXj"
      },
      "source": [
        "# Build the neural network, expand on top of nn.Module\n",
        "class Network3(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    # define layers\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(3,3), padding=1)\n",
        "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3,3))\n",
        "    self.fc3 = nn.Linear(in_features=6*6*64,out_features=600)\n",
        "    self.fc4 = nn.Linear(in_features=600,out_features=120)\n",
        "    self.fc5 = nn.Linear(in_features=120,out_features=10)\n",
        "    self.mxpool = nn.MaxPool2d(kernel_size=(2,2),stride = (2,2))\n",
        "    self.drop = nn.Dropout2d(0.25)\n",
        "\n",
        "  # define forward function\n",
        "  def forward(self, t):\n",
        "    # fc 1\n",
        "    t=self.conv1(t)\n",
        "    t=F.relu(t)\n",
        "    t = self.mxpool(t)\n",
        "    t = self.drop(t)\n",
        "    # fc 2\n",
        "    t=self.conv2(t)\n",
        "    t=F.relu(t)\n",
        "    t = self.mxpool(t)\n",
        "\n",
        "    t = torch.flatten(t,1)\n",
        "    t = self.fc3(t)\n",
        "    t = F.relu(t)\n",
        "    t = self.drop(t)\n",
        "    t = self.fc4(t)\n",
        "    t = F.relu(t)\n",
        "    t = self.fc5(t)\n",
        "    # t = F.log_softmax(t, dim=1)    \n",
        "\n",
        "    return t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erByk_mhPAXs",
        "outputId": "649fd7d4-7cad-4be3-c4ec-2d69d29c0ede"
      },
      "source": [
        "network = Network3()\n",
        "train_test_network(network)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: train set accuracy 0.79345\n",
            "Epoch 1: train set accuracy 0.8428333333333333\n",
            "Epoch 2: train set accuracy 0.8667166666666667\n",
            "Epoch 3: train set accuracy 0.8826166666666667\n",
            "Epoch 4: train set accuracy 0.89135\n",
            "Epoch 5: train set accuracy 0.89755\n",
            "Epoch 6: train set accuracy 0.9056666666666666\n",
            "Epoch 7: train set accuracy 0.9067333333333333\n",
            "Epoch 8: train set accuracy 0.9129166666666667\n",
            "Epoch 9: train set accuracy 0.9158333333333334\n",
            "Epoch 9: test set accuracy 0.899\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G22feDZGPZm8"
      },
      "source": [
        "## Variation 2 model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOPKVr8kPndV"
      },
      "source": [
        "# Build the neural network, expand on top of nn.Module\n",
        "class Network4_1(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    # define layers\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(3,3), padding=1)\n",
        "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3,3))\n",
        "    self.fc3 = nn.Linear(in_features=6*6*64,out_features=600)\n",
        "    self.fc4 = nn.Linear(in_features=600,out_features=120)\n",
        "    self.fc5 = nn.Linear(in_features=120,out_features=10)\n",
        "    self.mxpool = nn.MaxPool2d(kernel_size=(2,2),stride = (2,2))\n",
        "    self.drop = nn.Dropout2d(0.25)\n",
        "    self.batchnorm1 = nn.BatchNorm2d(32)\n",
        "    self.batchnorm2 = nn.BatchNorm2d(64)\n",
        "\n",
        "\n",
        "  # define forward function\n",
        "  def forward(self, t):\n",
        "    # conv1 1\n",
        "    t=self.conv1(t)\n",
        "    t = self.batchnorm1(t)\n",
        "    t=F.relu(t)\n",
        "    t = self.mxpool(t)\n",
        "\n",
        "    # conv 2\n",
        "    t=self.conv2(t)\n",
        "    t = self.batchnorm2(t)\n",
        "\n",
        "    t=F.relu(t)\n",
        "    t = self.mxpool(t)\n",
        "\n",
        "    t = torch.flatten(t,1)\n",
        "    t = self.fc3(t)\n",
        "    t = F.relu(t)\n",
        "    t = self.drop(t)\n",
        "    t = self.fc4(t)\n",
        "    t = F.relu(t)\n",
        "    t = self.fc5(t)\n",
        "    # t = F.log_softmax(t, dim=1)    \n",
        "\n",
        "    return t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzxpuGaQPndW",
        "outputId": "15975471-018a-421f-9304-f5b5153d9297"
      },
      "source": [
        "network = Network4_1()\n",
        "train_test_network(network, epochs=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: train set accuracy 0.8748833333333333\n",
            "Epoch 1: train set accuracy 0.9016833333333333\n",
            "Epoch 2: train set accuracy 0.9124833333333333\n",
            "Epoch 3: train set accuracy 0.9234333333333333\n",
            "Epoch 4: train set accuracy 0.9285666666666667\n",
            "Epoch 5: train set accuracy 0.9366166666666667\n",
            "Epoch 6: train set accuracy 0.9332833333333334\n",
            "Epoch 7: train set accuracy 0.9205666666666666\n",
            "Epoch 8: train set accuracy 0.9479833333333333\n",
            "Epoch 9: train set accuracy 0.9549\n",
            "Epoch 9: test set accuracy 0.9186\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}